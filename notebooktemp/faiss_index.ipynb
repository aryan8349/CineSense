{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ac8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcbbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"../Data/netflix_data_with_links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['type_encoded'] = data['type'].map({'Movie':1,'TV Show':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['rating_encoded'] = le.fit_transform(data['rating'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "data['country'] = data['country'].fillna('Unknown')\n",
    "data['country_split'] = data['country'].str.split(',')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "country_encoded = mlb.fit_transform(data['country_split'])\n",
    "\n",
    "country_df = pd.DataFrame(country_encoded, columns = mlb.classes_)\n",
    "data = pd.concat([data,country_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85428076",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['listed_in'] = data['listed_in'].fillna('Unknown')\n",
    "data['genre_split'] = data['listed_in'].str.split(',')\n",
    "mlb_genre = MultiLabelBinarizer()\n",
    "genre_encoded = mlb_genre.fit_transform(data['genre_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_minutes(x):\n",
    "    try:\n",
    "        if 'min' in str(x):\n",
    "            return int(x.split()[0])\n",
    "        else:\n",
    "            return 0\n",
    "    except :\n",
    "        return 0\n",
    "data['duration_minutes'] = data['duration'].fillna('0 min').apply(extract_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['release_year'] = data['release_year'].fillna(0).astype(int)\n",
    "data['release_month'] = pd.to_datetime(data['date_added'], errors = 'coerce').dt.month.fillna(0).astype(int)\n",
    "data['release_decade'] = (data['release_year'] //10)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27588530",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genre_count'] = data['genre_split'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f2fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['country'] = data['country'].fillna('Unknown')\n",
    "data['country_split'] = data['country'].str.split(',')\n",
    "country_counts = data['country_split'].explode().value_counts()\n",
    "top_countries = country_counts[country_counts > 50].index \n",
    "\n",
    "def group_countries(countries):\n",
    "    return [c if c in top_countries else 'Other' for c in countries]\n",
    "\n",
    "data['country_split'] = data['country_split'].apply(group_countries)\n",
    "\n",
    "genre_counts = data['genre_split'].explode().value_counts()\n",
    "top_genres = genre_counts[genre_counts > 50].index\n",
    "\n",
    "def group_genres(genres):\n",
    "    return [g if g in top_genres else 'Other' for g in genres]\n",
    "\n",
    "data['genre_split'] = data['genre_split'].apply(group_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56b5345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Movie Suggestion\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text = str(text).lower()\n",
    "#     text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "#     text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "#     return text\n",
    "\n",
    "# data['combined'] = (\n",
    "#     (data['listed_in'].fillna('') + ' ') * 3 +\n",
    "#     (data['description'].fillna('') + ' ') * 2 +\n",
    "#     data['director'].fillna('') + ' ' +\n",
    "#     data['cast'].fillna('') + ' ' +\n",
    "#     data['country'].fillna('') + ' ' +\n",
    "#     data['rating'].fillna('')\n",
    "# ).apply(clean_text)\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# embeddings = model.encode(data['combined'], show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "# # Save for future use\n",
    "# np.save(\"embeddings.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c6fb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = np.load(\"../model/embeddings.npy\")\n",
    "\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# embeddings = your numpy array of shape (n_samples, embedding_dim)\n",
    "faiss_index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss_index.add(embeddings)\n",
    "with open(\"faiss_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(faiss_index, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da1eb42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = np.load(\"embeddings.npy\")\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)  \n",
    "index.add(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e17272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_with_percentage(title, top_n=10, type_filter=None):\n",
    "    title_lower = title.lower().strip()\n",
    "    if title_lower not in data['title'].str.lower().values:\n",
    "        print(\"Movie not found\")\n",
    "        return []\n",
    "\n",
    "    idx = data[data['title'].str.lower() == title_lower].index[0]\n",
    "    vec = embeddings[idx].reshape(1, -1)\n",
    "    faiss.normalize_L2(vec)  # normalize the query vector\n",
    "\n",
    "    # Apply type filter\n",
    "    if type_filter:\n",
    "        filtered_idx = data[data['type'] == type_filter].index.to_numpy()\n",
    "        filtered_embeddings = embeddings[filtered_idx]\n",
    "        faiss.normalize_L2(filtered_embeddings)\n",
    "\n",
    "        index_temp = faiss.IndexFlatIP(filtered_embeddings.shape[1])\n",
    "        index_temp.add(filtered_embeddings)\n",
    "        D, I = index_temp.search(vec, min(top_n, len(filtered_embeddings)))\n",
    "        top_indices = filtered_idx[I[0]]\n",
    "        top_scores = D[0]\n",
    "    else:\n",
    "        D, I = index.search(vec, min(top_n + 1, len(data)))  # +1 to skip itself\n",
    "        top_indices = I[0][1:top_n+1] if len(I[0]) > 1 else []\n",
    "        top_scores = D[0][1:top_n+1] if len(D[0]) > 1 else []\n",
    "\n",
    "    recommended = [(data.iloc[i]['title'], round(score * 100, 1)) \n",
    "                   for i, score in zip(top_indices, top_scores)]\n",
    "    return recommended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48dcd84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kissing Game', np.float32(82.6)),\n",
       " ('Into the Night', np.float32(81.9)),\n",
       " ('Open Your Eyes', np.float32(81.1)),\n",
       " ('The Rain', np.float32(80.2)),\n",
       " ('Equinox', np.float32(79.4)),\n",
       " ('To the Lake', np.float32(79.2)),\n",
       " ('The Platform', np.float32(79.1)),\n",
       " ('Jinn', np.float32(78.8)),\n",
       " ('Good Morning, Ver√¥nica', np.float32(78.4)),\n",
       " ('Riverdale', np.float32(78.4))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_with_percentage('blood & water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2f1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
